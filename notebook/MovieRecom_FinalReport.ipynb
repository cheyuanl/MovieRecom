{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"svg\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from scipy import spatial\n",
    "from pandas import DataFrame as df\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collaborative_filtering as cf\n",
    "import linear_regression as lr\n",
    "import factorization_machine as fm\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from pyfm import pylibfm\n",
    "import movie_parsing\n",
    "import process_data\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "links = pd.read_csv('./data/ml-latest-small/links.csv')\n",
    "movies = pd.read_csv(\"./data/ml-latest-small/movies.csv\")\n",
    "ratings = pd.read_csv(\"./data/ml-latest-small/ratings.csv\")\n",
    "df_movies = pd.read_csv('./data/movie_objects.csv', encoding = 'utf-8')\n",
    "df_user = pd.read_csv(\"./data/u.user\",sep='|', \n",
    "                      names=['userId', 'age', 'gender', 'occupation', 'zip_code'], encoding = 'utf-8')[:671]\n",
    "\n",
    "reload(process_data)\n",
    "df_movies = movie_parsing.parse(df_movies)\n",
    "# df_movie_features, df_user_features = process_data.process(df_movies, df_user)\n",
    "# df_movie_features, df_user_features = df_movie_features.set_index('imdbId'), df_user_features.set_index('userId')\n",
    "ratings = ratings.merge(links, on = 'movieId')\n",
    "ratings = ratings.merge(df_movies, on ='imdbId')\n",
    "ratings = ratings.merge(df_user, on = 'userId')\n",
    "ratings.dropna(subset=['year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm\n",
    "from scipy.sparse import csr_matrix, vstack, hstack, csc_matrix\n",
    "import math\n",
    "\n",
    "np.random.seed(10)\n",
    "P = np.random.permutation(len(ratings))\n",
    "n = len(ratings)\n",
    "ratings_tr = ratings.iloc[P[:int(math.floor(9*n /10.))]]\n",
    "ratings_te = ratings.iloc[P[int(math.floor(9*n /10.)):]]\n",
    "\n",
    "def data_generate(row):\n",
    "    movie_feature = ['imdbId_onehot']\n",
    "    user_feature = ['userId_onehot']\n",
    "    \n",
    "    u = df_user_features.loc[int(row[1]['userId']), user_feature][0]\n",
    "    for uu in df_user_features.loc[int(row[1]['userId']), user_feature][1:]:\n",
    "        u = hstack(u, uu, format = 'csc')\n",
    "    v = df_movie_features.loc[int(row[1]['imdbId']), movie_feature][0]\n",
    "    for vv in df_movie_features.loc[int(row[1]['imdbId']), movie_feature][1:]:\n",
    "        v = hstack(v, vv, format = 'csc')\n",
    "        \n",
    "    return hstack((u, v))\n",
    "        \n",
    "    \n",
    "ratings_tr['data'] = map(data_generate, ratings_tr.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "# Collaberative Filtering\n",
    "reload(cf)\n",
    "X_tr, X_te, movieNames, idxToUserId, idxToLenId = cf.process(ratings, movies, np.random.permutation(len(ratings)))\n",
    "U_cf, V_cf = cf.train(X_tr, X_te, k = 3, lam = 1, niters = 0, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "reload(lr)\n",
    "V_lr, idxToImdbId = lr.process(df_movies, idxToLenId, links, features = ['year', 'votes', 'runtimes'])\n",
    "U_lr = lr.train(X_tr, V_lr, lam = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the experiement result comparing with the collaberative filtering method as a baseline, using the some evaluation metric. Although the training error is higher, the testing error is actually lower than the collaberative filtering method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "train_mse, test_mse = cf.error(X_tr, U_cf, V_cf), cf.error(X_te, U_cf, V_cf)\n",
    "print \"CF Train error: {:0.4f} Test error: {:0.4f}\".format(train_mse, test_mse)\n",
    "\n",
    "train_mse, test_mse = cf.error(X_tr, U_lr, V_lr), cf.error(X_te, U_lr, V_lr)\n",
    "print \"LR Train error: {:0.4f} Test error: {:0.4f}\".format(train_mse, test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same feature as linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "np.random.seed(10)\n",
    "P = np.random.permutation(len(ratings))\n",
    "n = len(ratings)\n",
    "ratings_tr = ratings.iloc[P[:int(math.floor(9*n /10.))]]\n",
    "ratings_te = ratings.iloc[P[int(math.floor(9*n /10.)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "reload(tokenizer)\n",
    "\n",
    "train_data, y_tr = tokenizer.tokenize(ratings_tr)\n",
    "test_data, y_te = tokenizer.tokenize(ratings_te)\n",
    "\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example (Rating matrix only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiemnt(X_train, y_tr, X_test, y_te, iters = [1,3,5,10,25,50], num_factor = 3):\n",
    "    models = []\n",
    "    train_error, test_error = [], []\n",
    "\n",
    "    for k in iters:\n",
    "        model = pylibfm.FM(num_factors=num_factor, num_iter=k,\n",
    "                        verbose=True, task=\"regression\",\n",
    "                        initial_learning_rate=1E-6, learning_rate_schedule=\"optimal\")\n",
    "        model.fit(X_train, y_tr)\n",
    "        models.append(model)\n",
    "\n",
    "        pred = model.predict(X_train)\n",
    "        train_error.append(mean_squared_error(y_tr, preds))\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        test_error.append(mean_squared_error(y_te, preds))\n",
    "\n",
    "        return models, train_error, test_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 5.19196\n",
      "-- Epoch 2\n",
      "Training MSE: 4.34369\n",
      "-- Epoch 3\n",
      "Training MSE: 3.20449\n",
      "-- Epoch 4\n",
      "Training MSE: 2.40837\n",
      "-- Epoch 5\n",
      "Training MSE: 1.85197\n",
      "-- Epoch 6\n",
      "Training MSE: 1.46310\n",
      "-- Epoch 7\n",
      "Training MSE: 1.19130\n",
      "-- Epoch 8\n",
      "Training MSE: 1.00132\n",
      "-- Epoch 9\n",
      "Training MSE: 0.86848\n",
      "-- Epoch 10\n",
      "Training MSE: 0.77559\n",
      "-- Epoch 11\n",
      "Training MSE: 0.71063\n",
      "-- Epoch 12\n",
      "Training MSE: 0.66516\n",
      "-- Epoch 13\n",
      "Training MSE: 0.63333\n",
      "-- Epoch 14\n",
      "Training MSE: 0.61102\n",
      "-- Epoch 15\n",
      "Training MSE: 0.59538\n",
      "-- Epoch 16\n",
      "Training MSE: 0.58438\n",
      "-- Epoch 17\n",
      "Training MSE: 0.57662\n",
      "-- Epoch 18\n",
      "Training MSE: 0.57115\n",
      "-- Epoch 19\n",
      "Training MSE: 0.56726\n",
      "-- Epoch 20\n",
      "Training MSE: 0.56448\n",
      "-- Epoch 21\n",
      "Training MSE: 0.56247\n",
      "-- Epoch 22\n",
      "Training MSE: 0.56101\n",
      "-- Epoch 23\n",
      "Training MSE: 0.55992\n",
      "-- Epoch 24\n",
      "Training MSE: 0.55910\n",
      "-- Epoch 25\n",
      "Training MSE: 0.55846\n",
      "-- Epoch 26\n",
      "Training MSE: 0.55795\n",
      "-- Epoch 27\n",
      "Training MSE: 0.55753\n",
      "-- Epoch 28\n",
      "Training MSE: 0.55718\n",
      "-- Epoch 29\n",
      "Training MSE: 0.55687\n",
      "-- Epoch 30\n",
      "Training MSE: 0.55659\n",
      "-- Epoch 31\n",
      "Training MSE: 0.55634\n",
      "-- Epoch 32\n",
      "Training MSE: 0.55610\n",
      "-- Epoch 33\n",
      "Training MSE: 0.55587\n",
      "-- Epoch 34\n",
      "Training MSE: 0.55565\n",
      "-- Epoch 35\n",
      "Training MSE: 0.55543\n",
      "-- Epoch 36\n",
      "Training MSE: 0.55522\n",
      "-- Epoch 37\n",
      "Training MSE: 0.55501\n",
      "-- Epoch 38\n",
      "Training MSE: 0.55481\n",
      "-- Epoch 39\n",
      "Training MSE: 0.55461\n",
      "-- Epoch 40\n",
      "Training MSE: 0.55440\n",
      "-- Epoch 41\n",
      "Training MSE: 0.55420\n",
      "-- Epoch 42\n",
      "Training MSE: 0.55400\n",
      "-- Epoch 43\n",
      "Training MSE: 0.55381\n",
      "-- Epoch 44\n",
      "Training MSE: 0.55361\n",
      "-- Epoch 45\n",
      "Training MSE: 0.55341\n",
      "-- Epoch 46\n",
      "Training MSE: 0.55321\n",
      "-- Epoch 47\n",
      "Training MSE: 0.55302\n",
      "-- Epoch 48\n",
      "Training MSE: 0.55282\n",
      "-- Epoch 49\n",
      "Training MSE: 0.55263\n",
      "-- Epoch 50\n",
      "Training MSE: 0.55243\n",
      "-- Epoch 51\n",
      "Training MSE: 0.55224\n"
     ]
    }
   ],
   "source": [
    "experiemnt(X_train, y_tr, X_test, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM MSE: 1.1066\n"
     ]
    }
   ],
   "source": [
    "preds = fm.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"FM MSE: %.4f\" % mean_squared_error(y_te, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_movie_features_bkup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
